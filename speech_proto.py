import os
import sys
import ssl
import json
import time
import base64
import queue
import asyncio
import websockets
import numpy as np
import sounddevice as sd

# ===== ì„¤ì • =====
MODEL = "gpt-4o-realtime-preview"  # ìµœì‹  í”„ë¦¬ë·° ëª¨ë¸
SAMPLE_RATE = 24000                # OpenAI Realtime ê¸°ë³¸ ê¶Œì¥
CHANNELS = 1
CHUNK_MS = 40                      # 40ms ë‹¨ìœ„ë¡œ ì „ì†¡
CHUNK_SAMPLES = int(SAMPLE_RATE * (CHUNK_MS / 1000.0))
DTYPE = np.int16
OPENAI_API_KEY = os.environ.get("OPENAI_API_KEY")

if not OPENAI_API_KEY:
    print("í™˜ê²½ë³€ìˆ˜ OPENAI_API_KEY ê°€ ì—†ìŠµë‹ˆë‹¤. ë¨¼ì € ì„¤ì •í•´ ì£¼ì„¸ìš”.")
    sys.exit(1)

# ===== ìœ í‹¸ =====
def pcm16_to_b64(pcm: np.ndarray) -> str:
    """int16 numpy PCM -> base64 str"""
    return base64.b64encode(pcm.tobytes()).decode("ascii")

def b64_to_pcm16(b64: str) -> np.ndarray:
    """base64 str -> int16 numpy PCM"""
    raw = base64.b64decode(b64)
    return np.frombuffer(raw, dtype=DTYPE)

# ===== ë…¹ìŒ / ì¬ìƒ =====
class AudioIO:
    def __init__(self, sample_rate=SAMPLE_RATE, channels=CHANNELS):
        self.sample_rate = sample_rate
        self.channels = channels
        self._in_q = queue.Queue()
        self._out_q = queue.Queue()
        self._in_stream = None
        self._out_stream = None

    def _in_callback(self, indata, frames, time_, status):
        if status:
            # print(f"[IN-STATUS] {status}")
            pass
        # monoë§Œ ì‚¬ìš©
        mono = indata[:, 0].copy() if indata.ndim > 1 else indata.copy()
        self._in_q.put(mono.astype(DTYPE))

    def _out_callback(self, outdata, frames, time_, status):
        if status:
            # print(f"[OUT-STATUS] {status}")
            pass
        try:
            chunk = self._out_q.get_nowait()
        except queue.Empty:
            chunk = np.zeros(frames, dtype=DTYPE)
        if len(chunk) < frames:
            padded = np.zeros(frames, dtype=DTYPE)
            padded[:len(chunk)] = chunk
            chunk = padded
        outdata[:, 0] = chunk  # mono

    def start(self):
        self._in_stream = sd.InputStream(
            channels=1,
            samplerate=self.sample_rate,
            dtype=DTYPE,
            callback=self._in_callback,
            blocksize=CHUNK_SAMPLES,
        )
        self._out_stream = sd.OutputStream(
            channels=1,
            samplerate=self.sample_rate,
            dtype=DTYPE,
            callback=self._out_callback,
            blocksize=CHUNK_SAMPLES,
        )
        self._in_stream.start()
        self._out_stream.start()

    def stop(self):
        try:
            if self._in_stream: self._in_stream.stop(); self._in_stream.close()
            if self._out_stream: self._out_stream.stop(); self._out_stream.close()
        except Exception:
            pass

    def read_chunk(self, block=True, timeout=None) -> np.ndarray | None:
        try:
            return self._in_q.get(block=block, timeout=timeout)
        except queue.Empty:
            return None

    def play_chunk(self, pcm: np.ndarray):
        self._out_q.put(pcm)

# ===== Realtime WebSocket ì„¸ì…˜ =====
async def run_session():
    uri = f"wss://api.openai.com/v1/realtime?model={MODEL}"
    headers = [
        ("Authorization", f"Bearer {OPENAI_API_KEY}"),
        ("OpenAI-Beta", "realtime=v1"),
    ]
    # Windowsìš© ê¸°ë³¸ SSL ì»¨í…ìŠ¤íŠ¸
    ssl_context = ssl.create_default_context()

    audio = AudioIO()
    audio.start()
    print("ğŸ¤ ì¤€ë¹„ ì™„ë£Œ! Enterë¥¼ ëˆ„ë¥´ë©´ 3ì´ˆê°„ ë…¹ìŒ â†’ ì „ì†¡ â†’ ìŒì„±ì‘ë‹µ ì¬ìƒí•©ë‹ˆë‹¤. (q + Enter ë¡œ ì¢…ë£Œ)")

    async with websockets.connect(uri, additional_headers=headers, ssl=ssl_context, ping_interval=20, ping_timeout=20) as ws:

        async def receiver():
            """ì„œë²„ì—ì„œ ì˜¤ëŠ” ì´ë²¤íŠ¸ ìˆ˜ì‹ : output_audio.delta ë¥¼ ì¬ìƒ íì— ë°€ì–´ë„£ìŒ."""
            try:
                async for raw in ws:
                    msg = json.loads(raw)
                    t = msg.get("type")
                    if t == "response.created":
                        print("ğŸ¤– ì‘ë‹µ ìƒì„± ì‹œì‘")
                    elif t == "response.delta":
                        # í…ìŠ¤íŠ¸ í† í° ìŠ¤íŠ¸ë¦¼(ìˆì„ ìˆ˜ë„)
                        delta = msg.get("delta")
                        if isinstance(delta, str) and delta:
                            print(delta, end="", flush=True)
                    elif t == "response.output_text.delta":
                        # ìƒˆ í¬ë§·ì¼ ê²½ìš°
                        delta = msg.get("delta", "")
                        if delta:
                            print(delta, end="", flush=True)
                    elif t == "response.completed":
                        print("\nâœ… ì‘ë‹µ ì™„ë£Œ")
                    elif t == "output_audio.delta":
                        # ì˜¤ë””ì˜¤ ì¡°ê°(base64 PCM16)
                        b64 = msg.get("audio")
                        if b64:
                            pcm = b64_to_pcm16(b64)
                            audio.play_chunk(pcm)
                    elif t == "error":
                        print(f"\n[SERVER ERROR] {msg}")
                    # else:
                    #     print("[DBG EVT]", t, msg)
            except websockets.ConnectionClosed as e:
                print(f"[WS CLOSED] {e}")

        recv_task = asyncio.create_task(receiver())

        try:
            while True:
                user = input("> Enter = ë§í•˜ê¸° / q = ì¢…ë£Œ: ").strip().lower()
                if user == "q":
                    break

                # 1) 3ì´ˆ ë…¹ìŒ
                print("ğŸ™ 3ì´ˆ ë…¹ìŒ ì¤‘...")
                frames = []
                start_t = time.time()
                while time.time() - start_t < 3.0:
                    chunk = audio.read_chunk(timeout=0.1)
                    if chunk is not None:
                        frames.append(chunk)
                if not frames:
                    print("ë§ˆì´í¬ ì…ë ¥ì´ ì—†ìŠµë‹ˆë‹¤.")
                    continue
                pcm = np.concatenate(frames)

                # 2) ì˜¤ë””ì˜¤ ë²„í¼ append
                await ws.send(json.dumps({
                    "type": "input_audio_buffer.append",
                    "audio": pcm16_to_b64(pcm),
                }))
                # 3) commit
                await ws.send(json.dumps({"type": "input_audio_buffer.commit"}))

                # 4) ì‘ë‹µ ìƒì„± íŠ¸ë¦¬ê±° (ìŒì„± ì¶œë ¥ í¬í•¨)
                await ws.send(json.dumps({
                    "type": "response.create",
                    "response": {
                        "modalities": ["audio", "text"],
                        "instructions": "You are CarePill, a friendly Korean medication assistant. Reply in Korean.",
                        "audio": {"voice": "alloy", "format": "pcm16", "sample_rate": SAMPLE_RATE},
                    }
                }))

                print("ğŸ“¨ ì „ì†¡ ì™„ë£Œ. ì‘ë‹µ ëŒ€ê¸° ì¤‘...")
                # receiver() íƒœìŠ¤í¬ê°€ ì˜¤ë””ì˜¤ë¥¼ ì¬ìƒí•´ì¤Œ

        finally:
            recv_task.cancel()
            audio.stop()

if __name__ == "__main__":
    try:
        asyncio.run(run_session())
    except KeyboardInterrupt:
        print("\nì¢…ë£Œí•©ë‹ˆë‹¤.")
